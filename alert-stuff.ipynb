{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction.\n",
    "Describe the project here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Settings\n",
    "The default Jupyter settings are a bit annoying.  Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=False\n",
    "\n",
    "# From https://stackoverflow.com/a/34058270/7077511\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals and Utility Code\n",
    "For the sake of convenience, I'm going to put some global functions and data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import dateutil.parser\n",
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "class utils:\n",
    "    # Path constants.\n",
    "    DATA_DIR = R'C:\\Users\\dma\\Documents\\twitch-analytics\\data'\n",
    "    \n",
    "    @staticmethod\n",
    "    def rel_data(relpath: str):\n",
    "        return os.path.join(utils.DATA_DIR, relpath)\n",
    "    \n",
    "    # Matches either YouTube style (\"PT52M3S\") or Twitch style (\"4h10m52s\").\n",
    "    _re_duration = re.compile(R'(PT)?((\\d+)[Hh])?((\\d+)[Mm])?((\\d+)[Ss])?')\n",
    "    @staticmethod\n",
    "    def parse_duration(data: str):\n",
    "        if (m := utils._re_duration.match(data)):\n",
    "            duration = timedelta(\n",
    "                hours   = int(m.group(3)) if m.group(3) else 0,\n",
    "                minutes = int(m.group(5)) if m.group(5) else 0, \n",
    "                seconds = int(m.group(7)) if m.group(7) else 0)\n",
    "\n",
    "            return duration\n",
    "        \n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def make_int(data: Union[str, int, None]) -> Optional[int]:\n",
    "        if (data is None) or (len(data) == 0):\n",
    "            return None\n",
    "\n",
    "        return int(data)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_str(data: str) -> Optional[str]:\n",
    "        if (data is None):\n",
    "            return None\n",
    "\n",
    "        r = data.rstrip()\n",
    "        if (len(data) == 0):\n",
    "            return None\n",
    "\n",
    "        return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://store.steampowered.com/api/appdetails?appids=41014\n",
    "# https://steamdb.info/app/543260/config/\n",
    "import os\n",
    "import json\n",
    "\n",
    "# https://store.steampowered.com/dynamicstore/userdata/\n",
    "with open(\"data/my-games.json\") as json_file:\n",
    "    my_games = json.load(json_file)\n",
    "\n",
    "# https://api.steampowered.com/ISteamApps/GetAppList/v0002/?format=json\n",
    "with open(\"data/steam-games.json\", encoding=\"utf-8\") as json_file:\n",
    "    steam_games = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "done = set([220,7670,21090,22330,70300,72850,201810,205100,221100,264710,362890,379720,397950,403640,480490,782330,848450])\n",
    "\n",
    "apps = dict((x[\"appid\"], x[\"name\"]) for x in steam_games[\"applist\"][\"apps\"])\n",
    "todo = dict([(x, apps.get(x, None)) for x in my_games[\"rgOwnedApps\"] if x not in done])\n",
    "\n",
    "for x in todo:\n",
    "    if todo[x]:\n",
    "        print(todo[x].strip(), x, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_twitch_games = {\n",
    "  \"data\": [\n",
    "      {\n",
    "        \"box_art_url\": \"https://static-cdn.jtvnw.net/ttv-boxart/506442_IGDB-{width}x{height}.jpg\",\n",
    "        \"id\": \"506442\",\n",
    "        \"name\": \"DOOM Eternal\"\n",
    "      },\n",
    "      {\n",
    "        \"box_art_url\": \"https://static-cdn.jtvnw.net/ttv-boxart/511212_IGDB-{width}x{height}.jpg\",\n",
    "        \"id\": \"511212\",\n",
    "        \"name\": \"Subnautica: Below Zero\"\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "atg = dict([(int(x[\"id\"]), x) for x in all_twitch_games['data']])\n",
    "\n",
    "stuff=[]\n",
    "\n",
    "import urllib.parse\n",
    "\n",
    "for x in stuff:\n",
    "    g = atg.get(x)\n",
    "    print(x, g[\"name\"], g[\"box_art_url\"], \"https://www.twitch.tv/directory/game/\" + urllib.parse.quote(g[\"name\"]), sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"data/my-games.txt\", encoding=\"utf-8\") as txt_file:\n",
    "    df = pd.read_csv(txt_file, sep='\\t', header=0, dtype={\"youtube_url\": 'str'})\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mapping of process names to Twitch game IDs.\n",
    "PROC_GAMES = {\n",
    "    \"BioshockHD.exe\":                       15866,          # Actually it's the remaster (2009742488), but who cares?\n",
    "    \"Clustertruck.exe\":                     491398,\n",
    "    \"DOOMEternalx64vk.exe\":                 506442,\n",
    "    \"DOOMx64.exe\":                          6715,\n",
    "    \"DayZ_x64.exe\":                         65632,\n",
    "    \"Dead Space.exe\":                       19009,\n",
    "    \"Dishonored.exe\":                       32156,\n",
    "    \"Dishonored2.exe\":                      490348,\n",
    "    \"Dishonored_DO.exe\":                    497438,\n",
    "    \"Fallout4.exe\":                         489776,\n",
    "    \"FortniteClient-Win64-Shipping.exe\":    33214,\n",
    "    \"Oblivion.exe\":                         18526,\n",
    "    \"Prey.exe\":                             15013,\n",
    "    \"Subnautica.exe\":                       460090,\n",
    "    \"SubnauticaZero.exe\":                   511212,\n",
    "    \"WolfNewOrder_x64.exe\":                 369259,\n",
    "    \"bms.exe\":                              68016,\n",
    "    \"hl2.exe\":                              1420,\n",
    "    \"wb.exe\":                               495060,\n",
    "    \n",
    "}\n",
    "\"LockApp.exe\", \"chrome.exe\", \"explorer.exe\", \"ApplicationFrameHost.exe\", \"unknown\", \"Steam.exe\", \"steam.exe\", \"Discord.exe\", \"NVIDIA Share.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import time\n",
    "\n",
    "games = []\n",
    "json_games = dict()\n",
    "\n",
    "with open(\"data/my-games.txt\", encoding=\"utf-8\") as txt_file:\n",
    "    re_jpg = re.compile(R'<meta content=\"(//images\\.igdb\\.com/igdb/image/upload/t_cover_big/.+?\\.jpg)\"')\n",
    "    re_id = re.compile(R'<meta id=\"pageid\" content=\"game\" data-game-id=\"(\\d+)\" ')\n",
    "    \n",
    "    r = csv.DictReader(txt_file, delimiter='\\t', quotechar='|')\n",
    "    for row in r:\n",
    "        igdb_id = None\n",
    "        igdb_box_art_url = None\n",
    "        \n",
    "        with open(f\"data/igdb/{row['game_id']}.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if (m := re_jpg.search(line)):\n",
    "                    igdb_box_art_url = \"https:\" + m.group(1)\n",
    "\n",
    "                if (m := re_id.search(line)):\n",
    "                    igdb_id = int(m.group(1))\n",
    "\n",
    "        json_games[utils.make_int(row[\"game_id\"])] = {\n",
    "            \"game_id\":              utils.make_int(row[\"game_id\"]),\n",
    "            \"game_name\":            utils.make_str(row[\"game_name\"]),\n",
    "            \"twitch_box_art_url\":   utils.make_str(row[\"twitch_box_art_url\"]),\n",
    "            \"twitch_game_url\":      utils.make_str(row[\"twitch_game_url\"]),\n",
    "            \"youtube_game_url\":     utils.make_str(row[\"youtube_game_url\"]),\n",
    "            \"game_source\":          \"Steam\",\n",
    "            \"igdb_id\":              igdb_id,\n",
    "            \"igdb_url\":             utils.make_str(row[\"igdb_url\"]),\n",
    "            \"igdb_box_art_url\":     igdb_box_art_url,\n",
    "            \"steam_app_id\":         utils.make_int(row[\"steam_app_id\"]),\n",
    "            \"steam_url\":            utils.make_str(row[\"steam_url\"]),\n",
    "            \"gog_url\":              utils.make_str(row[\"gog_url\"]),\n",
    "            \"epic_url\":             utils.make_str(row[\"epic_url\"])\n",
    "            # \"config_url\":           \"https://steamdb.info/app/\" + str(utils.make_int(row[\"steam_app_id\"])) + \"/config/\"\n",
    "        }\n",
    "        \n",
    "        games.append((\n",
    "            utils.make_int(row[\"game_id\"]), \n",
    "            utils.make_str(row[\"game_name\"]), \n",
    "            utils.make_str(row[\"twitch_box_art_url\"]), \n",
    "            utils.make_str(row[\"twitch_game_url\"]), \n",
    "            utils.make_str(row[\"youtube_game_url\"]),\n",
    "            \"Steam\",\n",
    "            igdb_id,\n",
    "            utils.make_str(row[\"igdb_url\"]),\n",
    "            igdb_box_art_url,\n",
    "            utils.make_int(row[\"steam_app_id\"]),\n",
    "            utils.make_str(row[\"steam_url\"]),\n",
    "            utils.make_str(row[\"gog_url\"]),\n",
    "            utils.make_str(row[\"epic_url\"])\n",
    "        ))\n",
    "\n",
    "with open(\"ref-data/games.json\", \"w\") as f:\n",
    "    json.dump(json_games, f, ensure_ascii=False, sort_keys=True, indent='  ')\n",
    "\n",
    "print(json.dumps(json_games, indent='  '))\n",
    "# display(games)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now insert all games into the Games table.\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"data/dmatech.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.executemany('''\n",
    "    INSERT INTO Games (\n",
    "        game_id, game_name, twitch_box_art_url, twitch_game_url, youtube_game_url, game_source,\n",
    "        igdb_id, igdb_url, igdb_box_art_url, steam_app_id, steam_url, gog_url, epic_url\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "''', games)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, load the VideoSnapshots table.\n",
    "import glob\n",
    "videos = []\n",
    "\n",
    "# First, load everything discovered using \"tcd\".\n",
    "for fn in glob.glob(\"data/chat-logs/*.json\"):\n",
    "    time_stamp = float(os.path.getmtime(fn))\n",
    "    \n",
    "    with open(fn) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        v = data['video']\n",
    "        \n",
    "        video_id = int(v[\"id\"])\n",
    "        stream_id = None\n",
    "        \n",
    "        # Some of the TCD output actually has the stream ID.\n",
    "        if \"stream_id\" in v:\n",
    "            stream_id = int(v[\"stream_id\"])\n",
    "        \n",
    "        videos.append((video_id, stream_id, time_stamp, \"tcd\", json.dumps(v)))\n",
    "\n",
    "# Get the stuff from the new \"helix\" API.\n",
    "# twitch api get videos -P -q user_id=217476645 > videos_2022-06-04.json\n",
    "# scp -p 192.168.1.19:/home/dma/twitch-logs/dmatech/videos_*.json .\n",
    "for fn in glob.glob(\"data/more-json/videos_*.json\"):\n",
    "    time_stamp = float(os.path.getmtime(fn))\n",
    "    \n",
    "    with open(fn) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        for v in data[\"data\"]:\n",
    "            video_id = int(v[\"id\"])\n",
    "            stream_id = None\n",
    "\n",
    "            if \"stream_id\" in v:\n",
    "                stream_id = int(v[\"stream_id\"])\n",
    "\n",
    "            videos.append((video_id, stream_id, time_stamp, \"helix\", json.dumps(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now insert it into the VideoSnapshots table.\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"data/dmatech.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.executemany('''\n",
    "    INSERT INTO VideoSnapshots (video_id, stream_id, time_stamp, json_format, json_data)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "''', videos)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# display(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an overview of IRC logs\n",
    "irc_logs = []\n",
    "json_irc_logs = []\n",
    "\n",
    "with open(\"data/irc-logs.txt\", encoding=\"utf-8\") as txt_file:\n",
    "    r = csv.DictReader(txt_file, delimiter='\\t', quotechar='|')\n",
    "    for row in r:\n",
    "        print(f\"[{row['min_ts']:>12}, {row['max_ts']:>12}, {row['xz_size']:>12}, \\\"{row['xz_sha256sum']}, \\\"{row['xz_path']}\\\"],\")\n",
    "        \n",
    "        json_irc_logs.append({\n",
    "            \"xz_path\": row[\"xz_path\"],\n",
    "            \"xz_sha256sum\": row[\"xz_sha256sum\"],\n",
    "            \"xz_size\": utils.make_int(row[\"xz_size\"]),\n",
    "            \"min_ts\": utils.make_int(row[\"min_ts\"]),\n",
    "            \"max_ts\": utils.make_int(row[\"max_ts\"])\n",
    "        })\n",
    "\n",
    "json_irc_logs.sort(key=lambda x: x[\"min_ts\"], reverse=False)\n",
    "\n",
    "with open(\"ref-data/irc-logs.json\", \"w\") as f:\n",
    "    json.dump(json_irc_logs, f, ensure_ascii=False, sort_keys=True, indent='  ')\n",
    "\n",
    "print(json.dumps(json_irc_logs, indent='  '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://twitchtracker.com/dmatech/streams/39720122445\n",
    "# https://sullygnome.com/channel/dmatech/365/stream/45410307996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 836245698.json:\n",
    "with open(\"data/chat-logs/836245698.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    v_obj = data[\"video\"]\n",
    "    c_obj = data[\"comments\"][1]\n",
    "    ts = dateutil.parser.isoparse(c_obj['created_at']).timestamp()*1000\n",
    "    \n",
    "# From /home/dma/twitch-automation/logs/dmatech/rawlog-20201215.log.xz:\n",
    "# >> @badge-info=;badges=vip/1;color=;display-name=littlefox_o;emotes=;flags=;id=62f36cf0-9891-4197-8736-23f1d80b07a9;mod=0;room-id=217476645;subscriber=0;tmi-sent-ts=1607886088954;turbo=0;user-id=534604064;user-type= :littlefox_o!littlefox_o@littlefox_o.tmi.twitch.tv PRIVMSG #dmatech :Hello\n",
    "irc_ts = 1607886088954\n",
    "print(ts, irc_ts) # These line up perfectly.\n",
    "\n",
    "# This is close enough.\n",
    "tmp_ts = dateutil.parser.isoparse(v_obj[\"created_at\"]).timestamp() + float(c_obj[\"content_offset_seconds\"])\n",
    "print(tmp_ts*1000)\n",
    "\n",
    "# The question is...  How does this relate to the timestamps in the OBS logs?  \n",
    "# Where in a .mkv recording would a chat event be?\n",
    "# To figure this out, I need to determine corresponding frames in the mkv and mp4 for\n",
    "# a bunch of videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display two objects for comparison.\n",
    "print(json.dumps(v_obj, indent='\\t'))\n",
    "print(json.dumps(c_obj, indent='\\t'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ref-data/irc-logs.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "print(type(data[0][\"max_ts\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
