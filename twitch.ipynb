{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "All videos that are part of this exercise have accompanying OBS logs, so the analysis will start with those.  Recordings to `.mkv` files have the explicit filename in the log, but Twitch video ID numbers are not present.  Fortunately, the `.json` files downloaded with [`tcd`](https://pypi.org/project/tcd/) have timestamps and durations, and I should be able to match them up using the overlap of the time periods.\n",
    "\n",
    "# YouTube\n",
    "Seeing what got uploaded to the [dma's Twitch Archive](https://www.youtube.com/channel/UCWlc332uGYwHVPSTyDwFW-g) channel might be a bit more of a pain.  Some videos were uploaded using streaming-quality videos either copied across directly from Twitch or uploaded from a local `.mp4` file.  Others were uploaded using the `.mkv` file generated directly by OBS.  YouTube keeps the name of the file used for the upload, so I should be able to use this for matching in many cases.  In other cases, I made a manual link to the video ID in the YouTube description, so I should be able to use that.\n",
    "\n",
    "In order to access the channel with the ability to modify things, I'll need to be authenticated properly, and the [OAuth 2.0 Playground](https://developers.google.com/oauthplayground/) site should help with that.  [YouTube Data API v3](https://developers.google.com/youtube/v3/docs/) is used to modify and query videos, comments, playlists, and other YouTube objects.  I will need an OAuth 2.0 token supplied either through an `access_token` query parameter or an `Authorization: ` HTTP header.  \n",
    "\n",
    "```\n",
    "GET https://www.googleapis.com/youtube/v3/search?part=snippet&forMine=true&order=date&type=video&key=[YOUR_API_KEY] HTTP/1.1\n",
    "\n",
    "Authorization: Bearer [YOUR_ACCESS_TOKEN]\n",
    "Accept: application/json\n",
    "```\n",
    "\n",
    "Links:\n",
    "* [Google APIs](https://console.developers.google.com/)\n",
    "* [Google Cloud Platform](https://console.cloud.google.com/) (seems to be a superset of the API page)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Settings\n",
    "The default Jupyter settings are a bit annoying.  Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=False\n",
    "\n",
    "# From https://stackoverflow.com/a/34058270/7077511\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals and Utility Code\n",
    "For the sake of convenience, I'm going to put some global functions and data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class util:\n",
    "    # Path constants.\n",
    "    OBS_LOGS_DIR = R'C:\\Users\\dma\\AppData\\Roaming\\obs-studio\\logs'\n",
    "    DATA_DIR = R'C:\\Users\\dma\\Documents\\twitch-analytics\\data'\n",
    "    TWITCH_LOGS_DIR = R'C:\\Users\\dma\\Documents\\twitch-analytics\\data\\chat-logs'\n",
    "    \n",
    "    # Matches either YouTube style (\"PT52M3S\") or Twitch style (\"4h10m52s\").\n",
    "    _re_duration = re.compile(R'(PT)?((\\d+)[Hh])?((\\d+)[Mm])?((\\d+)[Ss])?')\n",
    "    @staticmethod\n",
    "    def parse_duration(data: str):\n",
    "        if (m := util._re_duration.match(data)):\n",
    "            duration = timedelta(\n",
    "                hours   = int(m.group(3)) if m.group(3) else 0,\n",
    "                minutes = int(m.group(5)) if m.group(5) else 0, \n",
    "                seconds = int(m.group(7)) if m.group(7) else 0)\n",
    "\n",
    "            return duration\n",
    "        \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obs_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "youtube_videos = []\n",
    "\n",
    "for fn in glob.glob(R'C:\\Users\\dma\\Documents\\twitch-analytics\\youtube\\details*.json'):\n",
    "    # print(fn)\n",
    "    \n",
    "    with open(fn) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        youtube_videos.extend(data[\"items\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of video files we actually have on disk.\n",
    "local_obs_mkv_files = glob.glob(R'G:\\Library\\Twitch\\OBS_Video\\*.mkv')\n",
    "local_twitch_mp4_files = glob.glob(R'G:\\Library\\Twitch\\Downloads\\*.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitch Chat Logs\n",
    "The initial pass is just getting the starting time and duration of each Twitch video.  Note that I didn't start downloading these until 2019-03-25.  Anything before that is a lost cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import List\n",
    "import dateutil.parser\n",
    "import pandas as pd\n",
    "\n",
    "@dataclass\n",
    "class TwitchVideo:\n",
    "    id: int\n",
    "    start_date: datetime\n",
    "    duration: timedelta\n",
    "    title : str\n",
    "    obj: object\n",
    "\n",
    "\n",
    "twitch_videos : List[TwitchVideo] = []\n",
    "\n",
    "for fn in glob.glob(R'C:\\Users\\dma\\Documents\\twitch-analytics\\data\\chat-logs\\*.json'):\n",
    "    with open(fn) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        v = data['video']\n",
    "        duration = util.parse_duration(v['duration'])\n",
    "        id = int(v[\"id\"])\n",
    "        twitch_videos.append(TwitchVideo(\n",
    "            id,\n",
    "            dateutil.parser.isoparse(v['created_at']).timestamp(),\n",
    "            duration, v['title'], v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBS Log Files\n",
    "OBS logs are annoying things.  Their timestamps don't have the dates, so I'll need to infer those from the file name itself.  In a couple files, the log spans multiple days (and this can be seen as OBS writes out a large number of records while the computer is locked overnight).  Fortunately, I always restart OBS before actually using it, so I shouldn't need to look for evidence of the clock passing midnight.\n",
    "    \n",
    "## Recording\n",
    "From `2019-11-24 18-16-57.txt`:\n",
    "```\n",
    "18:18:19.647: ==== Recording Start ===============================================\n",
    "18:18:19.647: [ffmpeg muxer: 'adv_file_output'] Writing file 'E:/OBS_Video/2019-11-24 18-18-19.mkv'...\n",
    "\n",
    "20:38:25.104: [ffmpeg muxer: 'adv_file_output'] Output of file 'E:/OBS_Video/2019-11-24 18-18-19.mkv' stopped\n",
    "20:38:25.104: Output 'adv_file_output': stopping\n",
    "20:38:25.104: Output 'adv_file_output': Total frames output: 504318\n",
    "20:38:25.104: Output 'adv_file_output': Total drawn frames: 504326 (504327 attempted)\n",
    "20:38:25.104: Output 'adv_file_output': Number of lagged frames due to rendering lag/stalls: 1 (0.0%)\n",
    "20:38:25.104: ==== Recording Stop ================================================\n",
    "```\n",
    "\n",
    "## Streaming\n",
    "From `2019-11-24 18-16-57.txt`:\n",
    "```\n",
    "18:18:20.599: [rtmp stream: 'adv_stream'] Connection to rtmp://live-iad.twitch.tv/app successful\n",
    "18:18:20.600: ==== Streaming Start ===============================================\n",
    "\n",
    "20:38:25.049: [rtmp stream: 'adv_stream'] User stopped the stream\n",
    "20:38:25.049: Output 'adv_stream': stopping\n",
    "20:38:25.049: Output 'adv_stream': Total frames output: 504259\n",
    "20:38:25.049: Output 'adv_stream': Total drawn frames: 504329 (504330 attempted)\n",
    "20:38:25.049: Output 'adv_stream': Number of lagged frames due to rendering lag/stalls: 1 (0.0%)\n",
    "20:38:25.049: ==== Streaming Stop ================================================\n",
    "```\n",
    "\n",
    "For reference, here is the relevant data from `512920284.json`, the matching Twitch log.  Note that the timestamps are in UTC and that they're lagged by several seconds.\n",
    "```js\n",
    "    \"video\": {\n",
    "        \"created_at\": \"2019-11-24T23:18:29Z\",\n",
    "        \"description\": \"\",\n",
    "        \"duration\": \"2h20m0s\",\n",
    "        \"id\": \"512920284\",\n",
    "        \"language\": \"en\",\n",
    "        \"published_at\": \"2019-11-24T23:18:29Z\",\n",
    "        // ...\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://stackoverflow.com/questions/33837918/type-hints-solve-circular-dependency\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import List, Set, Optional, Union\n",
    "import os\n",
    "import re\n",
    "import pytz\n",
    "import warnings\n",
    "\n",
    "# MKV files that are bad either due to running out of disk space or me screwing something up.\n",
    "# The equivalent MP4 files from the Twitch VODs will need to be used instead.\n",
    "MKV_BLACKLIST = [\n",
    "    # Ran out of space.\n",
    "    \"2019-07-04 09-05-11.mkv\",\n",
    "    \"2019-07-04 15-13-52.mkv\",\n",
    "    \"2019-07-06 09-00-03.mkv\",\n",
    "    \"2019-07-06 14-05-43.mkv\",\n",
    "    \"2019-07-11 20-26-32.mkv\",\n",
    "    \"2019-07-11 20-27-33.mkv\",\n",
    "    \"2019-07-17 19-27-48.mkv\",\n",
    "    \"2019-07-17 19-32-40.mkv\",\n",
    "    \"2019-07-20 13-41-11.mkv\",\n",
    "    \"2019-07-20 19-37-44.mkv\",\n",
    "    \n",
    "    # Accidentally forgot to record until the very end.\n",
    "    \"2020-08-14 08-59-20.mkv\",\n",
    "    \"2019-11-02 18-08-02.mkv\",\n",
    "    \n",
    "    # Recording of some training.\n",
    "    \"2022-03-31 13-24-25.mkv\",\n",
    "    \"2022-04-01 09-01-19.mkv\",\n",
    "    \n",
    "    # These were accidentally recorded at too low of a bitrate, so the Twitch VODs are better.\n",
    "    \"2022-04-09 18-53-34.mkv\",\n",
    "    \"2022-04-09 18-53-34.mkv\",\n",
    "    \"2022-04-10 17-01-21.mkv\",\n",
    "    \"2022-04-10 18-37-13.mkv\",\n",
    "    \"2022-04-23 14-25-01.mkv\",\n",
    "    \"2022-04-24 10-12-11.mkv\",\n",
    "    \"2022-04-24 14-46-01.mkv\",\n",
    "    \"2022-04-28 19-42-06.mkv\",\n",
    "    \"2022-04-30 16-31-33.mkv\",\n",
    "    \"2022-05-01 09-10-30.mkv\",\n",
    "    \"2022-05-01 19-58-20.mkv\",\n",
    "    \"2022-05-02 19-54-03.mkv\",\n",
    "    \"2022-05-03 20-02-46.mkv\",\n",
    "    \"2022-05-05 17-18-28.mkv\",\n",
    "    \"2022-05-06 17-50-31.mkv\",\n",
    "    \"2022-05-07 10-21-53.mkv\",\n",
    "    \"2022-05-07 15-44-28.mkv\",\n",
    "    \"2022-05-08 14-38-55.mkv\",\n",
    "    \"2022-05-14 09-50-20.mkv\",\n",
    "    \"2022-05-14 13-24-18.mkv\",\n",
    "    \"2022-05-15 14-02-22.mkv\",\n",
    "    \"2022-05-15 14-02-22.mkv\"\n",
    "]\n",
    "\n",
    "# These are not games.\n",
    "PROC_BLACKLIST = [\n",
    "    \"LockApp.exe\", \"chrome.exe\", \"explorer.exe\", \"ApplicationFrameHost.exe\", \n",
    "    \"unknown\", \"Steam.exe\", \"Discord.exe\"]\n",
    "\n",
    "class ObsLogEvent:\n",
    "    '''Meaningful event in an OBS log file.'''\n",
    "\n",
    "    def __init__(self, event_type: str, start_time: int):\n",
    "        # Members.\n",
    "        self.event_type : str = event_type\n",
    "        self.start_time : int = start_time\n",
    "        self.end_time : int = None\n",
    "        \n",
    "        # Output file used for a recording.\n",
    "        self.mkv_file : str = None\n",
    "            \n",
    "        # YouTube video object (for recordings).\n",
    "        self.youtube_video : object = None\n",
    "        \n",
    "        # ID number of Twitch video (for streams).\n",
    "        self.twitch_id : int = None\n",
    "        \n",
    "        # Twitch video object (for streams).\n",
    "        self.twitch_video : TwitchVideo = None\n",
    "        \n",
    "        # Related events (i.e. those with overlapping timestamps).\n",
    "        self.related : List[ObsLogEvent] = []\n",
    "        \n",
    "    def find_youtube_video(self):  \n",
    "        # Find the YouTube video if possible.\n",
    "        if (self.event_type == 'Recording'):\n",
    "            mkv_base = os.path.basename(self.mkv_file)\n",
    "\n",
    "            for v in youtube_videos:\n",
    "                if v[\"fileDetails\"][\"fileName\"] == mkv_base:\n",
    "                    self.youtube_video = v\n",
    "                    break\n",
    "        elif (self.event_type == 'Stream' and self.twitch_id is not None):\n",
    "            for v in youtube_videos:\n",
    "                if v[\"fileDetails\"][\"fileName\"].startswith(str(self.twitch_id) + \"-\"):\n",
    "                    self.youtube_video = v\n",
    "                    break\n",
    "            \n",
    "            \n",
    "    def add_related(self, other: ObsLogEvent):\n",
    "        if (other is not None and other is not self):\n",
    "            # Make sure duplicates aren't inserted.  Considering that this list will usually\n",
    "            # only have one value, this should be efficient enough.\n",
    "            for i in self.related:\n",
    "                if (i is other):\n",
    "                    return\n",
    "            \n",
    "            self.related.append(other)\n",
    "        \n",
    "  \n",
    "class ObsLogFile:\n",
    "    '''OBS log file.'''\n",
    "    \n",
    "    re_filename = re.compile(\"\\\\\\\\(\\\\d\\\\d\\\\d\\\\d-\\\\d\\\\d-\\\\d\\\\d) \\\\d\\\\d-\\\\d\\\\d-\\\\d\\\\d\\.txt\")\n",
    "    re_line = re.compile(\"^(..:..:..\\\\....): (\\\\[ffmpeg muxer: 'adv_file_output'\\\\] Writing file '(.*)'\\\\.\\\\.\\\\.|==== ((Recording|Streaming) (Start|Stop)) ======+)$\")\n",
    "    re_hook = re.compile(\"^.*attempting to hook fullscreen process: (.*)\")\n",
    "    \n",
    "    def load_data(self):\n",
    "        # Parse the filename itself to get the date.\n",
    "        m = ObsLogFile.re_filename.search(self.filename)\n",
    "        if m:\n",
    "            date = m.group(1)\n",
    "        \n",
    "        # ...\n",
    "        current_recording : ObsLogEvent = None\n",
    "        current_stream : ObsLogEvent = None\n",
    "        \n",
    "        # Read through the file and pick out useful bits.\n",
    "        with open(self.filename, \"r\") as f:\n",
    "            line_num = 0\n",
    "            for line in f:\n",
    "                line_num = line_num + 1\n",
    "                \n",
    "                if (m := ObsLogFile.re_line.match(line)):\n",
    "                    # Get the time and date.\n",
    "                    # dt = datetime.strptime(date + \" \" + m.group(1), \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "                    dt = dateutil.parser.isoparse(date + \"T\" + m.group(1)).timestamp()\n",
    "\n",
    "                    # Process the actual line of the file.\n",
    "                    if (m.group(3)):\n",
    "                        current_recording.mkv_file = m.group(3)\n",
    "                        current_recording.find_youtube_video()\n",
    "                                              \n",
    "                    elif (m.group(4) == \"Recording Start\"):\n",
    "                        if (current_recording):\n",
    "                            raise Exception(\"Started a recording when one was already in progress.\", self.filename, line_num)\n",
    "\n",
    "                        current_recording = ObsLogEvent(\"Recording\", dt)\n",
    "                        \n",
    "                        # If simultaneously recording and streaming, associate the two activities.\n",
    "                        if current_recording and current_stream:\n",
    "                            current_stream.add_related(current_recording)\n",
    "                            current_recording.add_related(current_stream)\n",
    "                            \n",
    "                        self.events.append(current_recording)\n",
    "                        \n",
    "                    elif (m.group(4) == \"Recording Stop\"):\n",
    "                        if (not current_recording):\n",
    "                            raise Exception(\"Ended a recording when none was in progress.\", self.filename, line_num)\n",
    "\n",
    "\n",
    "                        current_recording.end_time = dt\n",
    "                        \n",
    "                        # If simultaneously recording and streaming, associate the two activities.\n",
    "                        if current_recording and current_stream:\n",
    "                            current_stream.add_related(current_recording)\n",
    "                            current_recording.add_related(current_stream)\n",
    "                            \n",
    "                        current_recording = None\n",
    "                    elif (m.group(4) == \"Streaming Start\"):\n",
    "                        if (current_stream):\n",
    "                            raise Exception(\"Started a stream when one was already in progress.\", self.filename, line_num)\n",
    "\n",
    "                        current_stream = ObsLogEvent(\"Stream\", dt)\n",
    "                        \n",
    "                        # If simultaneously recording and streaming, associate the two activities.\n",
    "                        if current_recording and current_stream:\n",
    "                            current_stream.add_related(current_recording)\n",
    "                            current_recording.add_related(current_stream)\n",
    "                            \n",
    "                        self.events.append(current_stream)\n",
    "                    elif (m.group(4) == \"Streaming Stop\"):\n",
    "                        if (not current_stream):\n",
    "                            # I'm reducing this one to a warning because it actually happened once.\n",
    "                            warnings.warn(Warning(\"Ended a stream when none was in progress.\", self.filename, line_num))\n",
    "                            continue\n",
    "\n",
    "                        current_stream.end_time = dt\n",
    "\n",
    "                        # See if we can find the Twitch ID for this video.  The Twitch timestamp appears\n",
    "                        # to lag about 9 seconds behind mine.\n",
    "                        ts_start = current_stream.start_time\n",
    "                        ts_end = current_stream.end_time\n",
    "                        for tv in twitch_videos:\n",
    "                            if tv.start_date > ts_start and tv.start_date < ts_end:\n",
    "                                if current_stream.twitch_id:\n",
    "                                    raise Exception(\"Found multiple twitch video IDs: \", tv, current_stream)\n",
    "                                    \n",
    "                                current_stream.twitch_id = tv.id\n",
    "                                current_stream.twitch_video = tv\n",
    "                                current_stream.find_youtube_video()\n",
    "                                \n",
    "                        if (not current_stream.twitch_id and current_stream.start_time > 1553513453 and (current_stream.end_time - current_stream.start_time > 120)):\n",
    "                            warnings.warn(Warning(\"Could not find Twitch video ID.\", self.filename, line_num))\n",
    "\n",
    "                        # If simultaneously recording and streaming, associate the two activities.\n",
    "                        if current_recording and current_stream:\n",
    "                            current_stream.add_related(current_recording)\n",
    "                            current_recording.add_related(current_stream)\n",
    "                            \n",
    "                        current_stream = None\n",
    "                elif (m := ObsLogFile.re_hook.match(line)):\n",
    "                    # This is a decent-enough way to determine what game I was playing for that session of OBS.\n",
    "                    # I don't think I ever played multiple games in one session.\n",
    "                    if (not m.group(1) in PROC_BLACKLIST):\n",
    "                        self.hooked_procs.add(m.group(1))\n",
    "                \n",
    "    def __init__(self, filename: str):\n",
    "        self.filename = filename\n",
    "        self.events : List[ObsLogEvent] = []\n",
    "        self.hooked_procs : Set[str] = set()\n",
    "        self.load_data()\n",
    "\n",
    "obs_logs : List[ObsLogFile] = []\n",
    "    \n",
    "for fn in sorted(glob.glob(R'C:\\Users\\dma\\AppData\\Roaming\\obs-studio\\logs\\20*.txt')):\n",
    "    print(fn)\n",
    "    obs_logs.append(ObsLogFile(fn))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Work\n",
    "I'm going to put all analysis below this point.  Everything above is loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find files that were uploaded more than once.\n",
    "df = pd.DataFrame({\n",
    "    'id': list(x[\"id\"] for x in youtube_videos),\n",
    "    'fileName': list(x[\"fileDetails\"][\"fileName\"] for x in youtube_videos)\n",
    "})\n",
    "\n",
    "display(df.groupby(['fileName']).count().sort_values(by='id', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display certain YouTube videos.  Just edit this query as needed.\n",
    "v = ([\n",
    "    x[\"fileDetails\"][\"fileName\"], \n",
    "    x[\"id\"], \n",
    "    x[\"contentDetails\"][\"duration\"],\n",
    "    x[\"status\"][\"privacyStatus\"],\n",
    "    x[\"snippet\"][\"title\"]\n",
    "] for x in youtube_videos if x[\"fileDetails\"][\"fileName\"] in [\n",
    "    \"2020-08-16 06-15-46.mkv\", \n",
    "    \"2020-08-09 14-00-45.mkv\",\n",
    "    \"2020-12-12 15-10-18.mkv\"])\n",
    "\n",
    "display(pd.DataFrame(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all videos that were uploaded from Twitch (as opposed to a .mp4 or mkv file).\n",
    "v = ([\n",
    "    x[\"fileDetails\"][\"fileName\"], \n",
    "    x[\"id\"], \n",
    "    x[\"contentDetails\"][\"duration\"],\n",
    "    x[\"status\"][\"privacyStatus\"],\n",
    "    x[\"snippet\"][\"title\"]\n",
    "] for x in youtube_videos if x[\"fileDetails\"][\"fileName\"] in [\"unknown\"])\n",
    "\n",
    "display(pd.DataFrame(v, columns=[\"fileName\", \"id\", \"duration\", \"privacyStatus\", \"title\"]).sort_values(by=\"title\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SetTitleRecord:\n",
    "    youtube_id: str\n",
    "    original_url: str\n",
    "    title: str\n",
    "    duration: str\n",
    "    created_at: str\n",
    "        \n",
    "TO_DO : List[SetTitleRecord] = []\n",
    "\n",
    "for olf in obs_logs:\n",
    "    for e in olf.events:\n",
    "        if e.event_type=='Recording':\n",
    "            twitch_ids = list(set([x.twitch_id for x in e.related if x.twitch_id]))\n",
    "            \n",
    "            if len(e.related) == 1 and e.related[0].twitch_video is not None:\n",
    "                # For these, there's exactly one Twitch video and one YouTube video.\n",
    "                yv = e.youtube_video\n",
    "                tv = None\n",
    "                if len(e.related) > 0:\n",
    "                    tv = e.related[0].twitch_video\n",
    "                \n",
    "                # TO_DO.append(SetTitleRecord())\n",
    "                # print(\"    \", e.__dict__)\n",
    "                # print(\"    \", e.related[0].twitch_video)\n",
    "                # print(\"    \", e.youtube_video)\n",
    "                print(\"    \", tv.id, tv.title)\n",
    "                if yv is None:\n",
    "                    print(\"     Not Uploaded:\", e.mkv_file)\n",
    "                else:\n",
    "                    print(\"    \", yv[\"id\"], yv[\"snippet\"][\"description\"], yv[\"snippet\"][\"title\"])\n",
    "                    \n",
    "                # These are ones we need to set.\n",
    "                if (yv is not None): # and (not yv[\"snippet\"][\"title\"].startswith(\"[0\") or not yv[\"snippet\"][\"description\"].startswith(\"Original\")):\n",
    "                    TO_DO.append({ \n",
    "                            \"current_title\": yv[\"snippet\"][\"title\"],\n",
    "                            \"youtube_id\": yv[\"id\"], \n",
    "                            \"original_url\": tv.obj[\"url\"],\n",
    "                            \"title\": tv.title.replace(\"#\", \"\"),\n",
    "                            \"duration\": tv.obj[\"duration\"],\n",
    "                            \"created_at\": tv.obj[\"created_at\"]\n",
    "                    })\n",
    "                    \n",
    "# This can be used in \"set-youtube.py\".\n",
    "print(json.dumps(TO_DO, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, make sure that all Twitch IDs are represented somewhere on YouTube.\n",
    "\n",
    "TO_DO : List[SetTitleRecord] = []\n",
    "\n",
    "for olf in obs_logs:\n",
    "    print(olf.filename, olf.hooked_procs)\n",
    "    for e in olf.events:\n",
    "        if e.event_type=='Stream':\n",
    "            if e.twitch_video is not None:\n",
    "                needs_mp4_vod = True\n",
    "\n",
    "                print(f\"  {e.twitch_video.id}, {e.twitch_video.obj['duration']}, {e.twitch_video.title}\")\n",
    "\n",
    "                # See if there's already a video uploaded from OBS.\n",
    "                for re in e.related:\n",
    "                    if (re.youtube_video is not None):\n",
    "                        print(f'    MKV already uploaded: {re.mkv_file} - {re.youtube_video[\"id\"]} - {re.youtube_video[\"snippet\"][\"title\"]}')\n",
    "                        needs_mp4_vod = False\n",
    "                    elif os.path.basename(re.mkv_file) in MKV_BLACKLIST:\n",
    "                        print(f'    Blacklisted MKV: {re.mkv_file}')\n",
    "                    else:\n",
    "                        print(f'    Consider uploading MKV: {re.mkv_file}')\n",
    "                        needs_mp4_vod = False\n",
    "\n",
    "                # See if the YouTube video is uploaded from one of the Twitch VODs.\n",
    "                if (e.youtube_video is not None):\n",
    "                    yv = e.youtube_video\n",
    "                    tv = e.twitch_video\n",
    "                    print(f'    {e.youtube_video[\"id\"]} - {e.youtube_video[\"snippet\"][\"title\"]}')\n",
    "                    TO_DO.append({ \n",
    "                            \"youtube_id\": yv[\"id\"], \n",
    "                            \"original_url\": tv.obj[\"url\"],\n",
    "                            \"title\": tv.title,\n",
    "                            \"duration\": tv.obj[\"duration\"],\n",
    "                            \"created_at\": tv.obj[\"created_at\"]\n",
    "                    })\n",
    "                    needs_mp4_vod = False\n",
    "                elif needs_mp4_vod:\n",
    "                    for z in local_twitch_mp4_files:\n",
    "                        if os.path.basename(z).startswith(str(e.twitch_video.id)):\n",
    "                            print(f'    Consider uploading this MP4: {z}')\n",
    "            else:\n",
    "                # There's a stream, but we don't have the JSON for it.\n",
    "                print(f'  Unknown stream that lasted {e.end_time - e.start_time} seconds.')\n",
    "            \n",
    "                \n",
    "            \n",
    "\n",
    "print(json.dumps(TO_DO, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a table of \n",
    "re_vodlink = re.compile(R'https://www.twitch.tv/videos/(\\d+)')\n",
    "re_part = re.compile(R'( *([\\[(]Part #?(\\d+)[\\])]|\\[#?0*(\\d+)\\]) *)')\n",
    "\n",
    "for yv in youtube_videos:\n",
    "    vod_id = None\n",
    "    probable_vod_id = None\n",
    "    part_num = None\n",
    "    title = yv[\"snippet\"][\"title\"]\n",
    "    \n",
    "    duration = util.parse_duration(yv[\"contentDetails\"][\"duration\"]).total_seconds()\n",
    "    \n",
    "    if (m := re_part.search(title)):\n",
    "        if (m.group(3) is not None):\n",
    "            part_num = int(m.group(3))\n",
    "\n",
    "        if (m.group(4) is not None):\n",
    "            part_num = int(m.group(4))\n",
    "            \n",
    "        title = re_part.sub(\"\", title)\n",
    "\n",
    "    # Try to find the VOD ID with the description.\n",
    "    if (m := re_vodlink.search(yv[\"snippet\"][\"description\"])):\n",
    "        vod_id = int(m.group(1))\n",
    "    \n",
    "    # See if there's a VOD with the same title and length.\n",
    "    for v in twitch_videos:\n",
    "        if v.title == yv[\"snippet\"][\"title\"]:\n",
    "            probable_vod_id = v.id\n",
    "    \n",
    "    if yv[\"fileDetails\"][\"fileName\"] == \"unknown\":\n",
    "        print(yv[\"id\"], vod_id, duration, yv[\"fileDetails\"][\"fileName\"], title, part_num, yv[\"snippet\"][\"title\"], sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in twitch_videos:\n",
    "    print(v.id, v.duration.total_seconds(), v.title, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
